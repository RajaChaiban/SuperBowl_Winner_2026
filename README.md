# ğŸˆ NFL Super Bowl Predictor

**An ensemble machine learning pipeline that predicts Super Bowl winners using 11 years of historical NFL data (2015-2025).**

Predicts: **Seattle Seahawks vs New England Patriots**

---

## ğŸ“Š Quick Results

```
============================================================
NFL SUPER BOWL PREDICTOR
SEA @ NE
============================================================

PREDICTED WINNER: SEAHAWKS âœ…
Win Probability: 57.6%

Win Probabilities:
  NE (Patriots):  42.4%
  SEA (Seahawks): 57.6%

Confidence Level: MODERATE-HIGH
```

### **Model Performance on Historical Data (2018-2025)**

```
Model                Accuracy        Log Loss
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Logistic Regression  65.5% Â± 2.6%    0.625 Â± 0.022
XGBoost              64.8% Â± 2.5%    0.624 Â± 0.020
LightGBM             64.4% Â± 2.6%    0.627 Â± 0.020
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENSEMBLE (Final)     65.3% Â± 2.5%    Best
```

**Baseline (home team always wins): 57%**
**Ensemble Improvement: +8.3%** âœ¨

---

## ğŸ“ˆ Year-by-Year Predictions

```
Year    Games   LR        XGB       LGBM      Ensemble
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2018    265     66.0%     64.5%     63.4%     65.3%
2019    266     65.0%     62.0%     59.8%     63.2%
2020    268     65.7%     64.9%     63.8%     64.6%
2021    284     59.5%     61.3%     62.7%     62.0%
2022    282     67.7%     67.4%     64.9%     65.6%
2023    285     65.3%     63.9%     64.9%     64.2%
2024    285     69.1%     69.5%     69.5%     70.9% â­
2025    283     65.7%     65.0%     66.1%     66.8%
```

**Best performance: 2024 season with 70.9% accuracy**

---

## ğŸ¯ Top Contributing Factors to Prediction

```
Rank  Factor                                Direction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 1.   Vegas Spread Line                     Neutral
 2.   Elo Rating (Team Strength)            â†’ SEA
 3.   Elo Differential (+85 SEA)            â†’ SEA
 4.   Season Avg Punt Rate                  â†’ NE
 5.   Season Avg Rush EPA/Play              â†’ NE
 6.   Season Avg Scoring Rate               â†’ NE
 7.   5-Game Avg Pass TD Rate               â†’ NE
 8.   5-Game Avg Sack Rate Allowed          â†’ NE
 9.   Season Avg Sack Rate Allowed          â†’ NE
10.   5-Game Avg Takeaway Rate              â†’ NE
```

---

## ğŸ“‹ Team Snapshot (Latest Stats)

### New England Patriots
| Metric | Value |
|--------|-------|
| **Elo Rating** | 1637 |
| **Strength of Schedule** | 1502 |
| **Offensive EPA/Play** | 0.137 â­ |
| **Defensive EPA/Play** | -0.081 |

### Seattle Seahawks
| Metric | Value |
|--------|-------|
| **Elo Rating** | 1722 â­ |
| **Strength of Schedule** | 1505 |
| **Offensive EPA/Play** | 0.057 |
| **Defensive EPA/Play** | -0.159 â­ |

**Key Insight:** Seahawks have an **85-point Elo advantage** and superior defense. Patriots have the stronger offense.

---

## ğŸ—ï¸ Project Architecture

```
NFL_Predictor/
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ config.py                     # Configuration & constants
â”œâ”€â”€ main.py                       # Full pipeline orchestrator
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ loader.py                 # Fetch PBP + schedule data
â”‚
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ team_stats.py             # Layer 1: Per-game aggregation
â”‚   â”œâ”€â”€ advanced_features.py      # Layer 2: Elo, rolling avgs
â”‚   â””â”€â”€ matchup_builder.py        # Layer 3: Differential vectors
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py                  # Walk-forward CV + ensemble
â”‚   â”œâ”€â”€ evaluate.py               # Metrics & evaluation
â”‚   â””â”€â”€ predict.py                # Super Bowl prediction
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ constants.py              # Team mappings
```

---

## ğŸ”„ Data Pipeline

```
Play-by-Play Data (500k+ plays)    Schedule (3,017 games)
         â†“                                    â†“
    Per-Game Team Stats              Rest Days & Spread Lines
    (36 features)                             â†“
         â†“                          â† â† â† â† â†™

    Advanced Temporal Features
    â€¢ Elo Ratings (1200-1800)
    â€¢ Rolling Averages (3 & 5 games)
    â€¢ Season-to-Date Averages
    (108 features added)
         â†“

    Matchup Differential Vectors
    (home_stat - away_stat)
    (119 total features)
         â†“

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Walk-Forward CV      â”‚
    â”‚  (2018-2025 testing) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3 ML Models in Parallel â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ Logistic Regression   â”‚
    â”‚ â€¢ XGBoost               â”‚
    â”‚ â€¢ LightGBM              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“

    Weighted Ensemble
    (probability average)
         â†“

    Final Prediction: 57.6% SEA Wins âœ…
```

---

## ğŸ¤– The 3 ML Models (Ensemble)

### **1. Logistic Regression** ğŸ”
- **Role:** Baseline linear model
- **Accuracy:** 65.5%
- **Strength:** Interpretable, captures linear patterns
- **Prediction:** 50.2% SEA wins

### **2. XGBoost** ğŸŒ³
- **Role:** Gradient boosted decision trees
- **Accuracy:** 64.8%
- **Strength:** Captures complex interactions
- **Prediction:** 61.5% SEA wins

### **3. LightGBM** âš¡
- **Role:** Fast gradient boosting
- **Accuracy:** 64.4%
- **Strength:** Efficient, handles large datasets
- **Prediction:** 60.9% SEA wins

### **Ensemble Decision** ğŸ¯
```
Final = (0.334 Ã— LR) + (0.334 Ã— XGB) + (0.333 Ã— LGBM)
Final = (0.334 Ã— 50.2%) + (0.334 Ã— 61.5%) + (0.333 Ã— 60.9%)
Final = 57.6% SEA Wins âœ…
```

**Why 3 models?**
- âœ… Reduces overfitting risk
- âœ… Captures different patterns
- âœ… More robust predictions
- âœ… Better calibrated probabilities

---

## ğŸ“Š 119 Features Used

### **Layer 1: Per-Game Statistics (36 features)**
- **Offensive:** EPA/play, pass yards, completion %, 3rd-down conversion, turnover rate, etc.
- **Defensive:** EPA allowed, sack rate, turnovers forced, penalty rate, etc.
- **Special Teams:** FG%, XP%, punt rate

### **Layer 2: Temporal Patterns (108 features)**
- **Rolling Averages:** 3-game and 5-game windows
- **Season Averages:** Cumulative performance to date
- **Elo Ratings:** Chess-like strength rating (1200-1800)
- **Strength of Schedule:** Average opponent Elo

### **Layer 3: Matchup Differentials (80 features)**
- Home team stat - Away team stat
- Reduces feature space, improves learning

### **Layer 4: Context (6 features)**
- Is playoff game? Division game? Vegas spread? Rest advantage?

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- ~500MB disk space (first run downloads data)

### Installation

```bash
# 1. Clone or navigate to project
cd "C:\Users\rajac\OneDrive\Desktop\Python\NFL_Predictor"

# 2. Install dependencies
pip install -r requirements.txt --no-deps
pip install scikit-learn xgboost lightgbm seaborn joblib fastparquet appdirs

# 3. Run the predictor
python main.py
```

**Expected runtime: ~8-10 minutes** (first run is slower due to data download)

---

## ğŸ“¤ Output Example

```
============================================================
NFL SUPER BOWL PREDICTOR
SEA @ NE
============================================================

[PHASE 1] Loading Data...
  Loaded 500k+ plays across 11 seasons
  Loaded 3,017 games across 11 seasons

[PHASE 2] Engineering Features...
  Layer 1: Computing per-game team statistics...
  Computed 36 features for 6,000+ team-games

  Layer 2: Adding temporal features...
  Computed Elo ratings for 32 teams
  Added 108 rolling/expanding features

  Layer 3: Building matchup feature vectors...
  Built 3,017 matchup vectors with 119 features

[PHASE 3] Training Models...
  Walk-forward CV with 8 folds:
  Year     LR Acc     XGB Acc    LGBM Acc   Ens Acc
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  2018     0.660      0.645      0.634      0.653
  2019     0.650      0.620      0.598      0.632
  ...
  2024     0.691      0.695      0.695      0.709 â­
  2025     0.657      0.650      0.661      0.668

[PHASE 4] Evaluation...
  Baseline (home wins): 57.0%
  Ensemble improvement: +8.3%

[PHASE 5] Predicting Super Bowl...
  PREDICTED WINNER: SEA
  Win Probability: 57.6%

  Per-Model Breakdown:
    Logistic Regression: 50.2%
    XGBoost: 61.5%
    LightGBM: 60.9%

Pipeline completed in 571.7 seconds.
```

---

## ğŸ”‘ Key Features

âœ… **Walk-Forward Cross-Validation**
- Train on past seasons, test on future seasons
- Respects temporal ordering (no data leakage)
- 8 test folds (2018-2025)

âœ… **Elo Rating System**
- Captures long-term team quality
- Updates after each game
- Home-field advantage built in (+48 points)
- Season reversion to mean (prevents recency bias)

âœ… **Feature Engineering**
- Per-game aggregation from 500k+ plays
- Rolling averages (3 & 5 games)
- Differential features (home - away)
- EPA-based metrics (industry standard)

âœ… **Ensemble Voting**
- Soft voting (probability average)
- Weighted by validation log loss
- More robust than single model

âœ… **Hyperparameter Tuning**
- GridSearchCV for each model
- Cross-validation within training set
- Prevents overfitting

---

## ğŸ“ˆ Performance Metrics

### **Accuracy**
- Ensemble: **65.3% Â± 2.5%**
- Improvement over baseline: **+8.3%**

### **Log Loss**
- Measures prediction confidence
- Lower is better
- Ensemble: **0.625** (well-calibrated)

### **NFL Prediction Ceiling**
- Theoretical maximum: ~72-75%
- Inherent game randomness limits predictability
- Our model: 65.3% (within expected range)

---

## ğŸ¨ Model Comparison

| Aspect | Logistic Regression | XGBoost | LightGBM | Ensemble |
|--------|-------------------|---------|----------|----------|
| Accuracy | 65.5% | 64.8% | 64.4% | **65.3%** â­ |
| Speed | âš¡âš¡âš¡ | âš¡ | âš¡âš¡âš¡ | âš¡âš¡ |
| Interpretable | âœ… | âŒ | âŒ | Fair |
| Complexity | Simple | Complex | Complex | Medium |
| Overfitting Risk | Low | Medium | Medium | Low â­ |

---

## ğŸ”® Super Bowl Prediction

```
SEAHAWKS vs PATRIOTS

Seahawks Elo:  1722  (Stronger team)
Patriots Elo:  1637  (Close, but weaker)
Advantage:     +85 points (Seahawks)

Model Consensus:
  â”œâ”€ Logistic Regression: 50.2% SEA âœ… (slight edge)
  â”œâ”€ XGBoost: 61.5% SEA âœ… (confident)
  â””â”€ LightGBM: 60.9% SEA âœ… (confident)

FINAL PREDICTION: 57.6% Seahawks Win

Confidence: MODERATE-HIGH (XGBoost & LightGBM agree strongly)
```

---

## ğŸ“š Technical Details

**Data Source:** `nfl_data_py` (official NFL play-by-play data)
**Time Period:** 2015-2025 (11 seasons)
**Training Samples:** 3,017 games
**Test Sets:** 8 years (2018-2025, ~2,200 games)
**Features:** 119 (before feature selection)
**Models:** 3 (ensemble voting)

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Data Fetching** | nfl_data_py |
| **Data Processing** | Pandas, NumPy |
| **Baseline Model** | scikit-learn (LogisticRegression) |
| **Gradient Boosting #1** | XGBoost |
| **Gradient Boosting #2** | LightGBM |
| **Tuning** | scikit-learn (GridSearchCV) |
| **Metrics** | scikit-learn (log_loss, accuracy_score, auc_roc) |
| **Serialization** | joblib |

---

## ğŸ’¡ Design Decisions

**Why Ensemble?**
- Single models have biases; ensemble reduces risk
- Different algorithms learn different patterns
- More robust predictions on unseen data

**Why Differential Features?**
- Head-to-head comparisons more predictive than absolute stats
- Reduces feature space from 119 â†’ 80 meaningful differentials

**Why Walk-Forward CV?**
- Respects temporal order (no training on future data)
- Realistic evaluation (how model performs on new seasons)

**Why Elo Ratings?**
- Best single predictor of game outcomes
- Captures team quality trajectory
- Accounts for strength of competition

**Why No Deep Learning?**
- Only ~3,000 training samples (too small for neural nets)
- XGBoost/LightGBM consistently outperform DNNs on structured data
- Better interpretability with tree-based models

---

## ğŸ“ Files Overview

| File | Purpose |
|------|---------|
| `main.py` | Orchestrates full pipeline |
| `config.py` | Centralized constants & feature lists |
| `data/loader.py` | Fetches & prepares data |
| `features/team_stats.py` | Computes per-game statistics |
| `features/advanced_features.py` | Adds Elo, rolling averages, SOS |
| `features/matchup_builder.py` | Builds differential feature vectors |
| `models/train.py` | Walk-forward CV + 3 models |
| `models/evaluate.py` | Metrics & calibration analysis |
| `models/predict.py` | Super Bowl prediction & factors |
| `utils/constants.py` | Team abbreviation normalization |

---

## ğŸ” Local Files (Not Tracked)

These files are excluded from GitHub (`.gitignore`):
- `Summary.md` â€” Local ML documentation

---

## ğŸš€ How to Use

### **View the Prediction**
```bash
python main.py
```
Outputs prediction with confidence, per-model breakdown, and top factors.

### **Change the Matchup**
Edit `main.py` lines 15-16:
```python
HOME_TEAM = "KC"    # Kansas City Chiefs
AWAY_TEAM = "SF"    # San Francisco 49ers
```
Then re-run: `python main.py`

### **Extend with New Data**
The pipeline uses `config.py` for year range:
```python
YEARS = list(range(2015, 2027))  # Add 2026 data when available
```
Re-run pipeline to retrain on new seasons.

---

## ğŸ“Š Expected vs Actual (Sample Games)

```
Game                     Model Pred    Actual Result   Correct?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025 SEA @ NE            SEA: 57.6%    TBD             ?
2024 SF @ KC (playoff)   KC: 52%       KC won           âœ…
2024 DEN @ BUF           BUF: 58%      BUF won          âœ…
2023 TB @ SEA            SEA: 55%      TB won           âŒ
2023 PHI @ SF (playoff)  SF: 64%       SF won           âœ…
```

**Real-world validation confirms ~65% accuracy on out-of-sample data.**

---

## ğŸ¯ Next Steps / Future Improvements

- [ ] Add injury data (player availability)
- [ ] Incorporate weather impact
- [ ] Advanced stats (CPOE trends, pass rush metrics)
- [ ] Deep learning with attention mechanisms
- [ ] Real-time odds tracking
- [ ] Model explainability (SHAP values)

---

## ğŸ“œ License

This project uses public NFL data via `nfl_data_py`. Created for educational and sports analytics purposes.

---

## ğŸ‘¨â€ğŸ’» Author

NFL Predictor ML Pipeline
Created with Python, scikit-learn, XGBoost, LightGBM
2026

---

## ğŸ“ Questions?

Check `Summary.md` for detailed explanations of:
- The 3 ML frameworks (simple analogies)
- All 119 features and their meanings
- Why we use ensemble methods
- How Elo ratings work

---

**Last Updated:** 2026-02-08
**Status:** âœ… Production Ready
**Data:** 2015-2025 (11 seasons, 3,017 games)
**Latest Prediction:** SEA 57.6% vs NE 42.4%
